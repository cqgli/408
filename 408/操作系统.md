# 计算机系统概述

## 计算机系统基本概念

#### 操作系统概念

1. 定义：控制和管理整个计算机系统的硬件和软件资源，合理的组织，调度计算机的工作与资源的分配，进而为用户和其他软件提供方便的接口和环境的程序集合

#### 操作系统的功能和目标

1. 操作系统作为计算机系统资源·的管理者
   1. 处理机管理：对进程的管理
   2. 存储器管理
   3. 文件管理
   4. 设备管理
2. 操作系统作为用户与计算机硬件系统之间的接口
   1. 命令接口
      1. 联机命令：交互式命令，执行一条命令
      2. 脱机命令：批处理命令，执行多个命令
   2. 程序接口
      1. 由一组系统调用组成
      2. 例：图形用户界面

#### 操作系统的特征

1. 并发
   1. 多个事件在同一个时间间隔内发生，**宏观的同时，微观不是同时**
2. 并行
   1. 同一时刻完成多个事件，同时
3. 共享
   1. 互斥共享
      1. 临界资源：一个资源不可以同时被两个进程访问
      2. 不同进程访问同一资源需要互相等待
      3. **不可在一个很短的时间内切换**
   2. 同时访问
      1. 在同一个时间间隔内，可以被不同进程访问，并发
      2. **在一个很短的时间内切换进程访问**
4. 虚拟
   1. **时分**：通过时间片虚拟化，实现“逻辑并行”，适合可分割的资源（如CPU）。
   2. **空分**：通过物理分区虚拟化，提供隔离性，适合需独占的资源（如内存）
5. 异步
   1. 多个进程并发进行，但是有时其他程序会堵塞

## 操作系统发展历程

#### 手工操作阶段

1. 缺点：用户独占全机，cpu利用不充分，效率低

#### 批处理阶段

1. 单道批处理
   1. 特点
      1. 自动性
      2. 顺序性
      3. 单道性
2. 多道批处理
   1. 特点
      1. 多道
      2. 宏观上并行
      3. 微观上串行
   2. 优点
      1. 资源利用率高
      2. 系统吞吐量大

#### 分时操作系统

1. 将cpu分成很多时间片，给不同的用户使用
2. 特点
   1. 同时性
   2. 交互性
   3. 独立性
   4. 及时性

#### 实时操作系统

1. 硬实时系统：某个动作必须在规定时间完成
2. 软实时系统：偶尔可以违反时间

#### 网络操作系统和分布式计算机

## 操作系统的运行环境

#### 处理器运行模式

1. 程序
   1. 内核程序
   2. 用户程序
2. 指令
   1. 特权指令
   2. 非特权指令
3. 运行状态
   1. 用户态
   2. 内核态
4. 时钟管理
5. 中断机制
6. 原语
   1. 位于操作系统底层
   2. 具有原子性
   3. 运行时间短
7. 系统控制的数据结构及处理
   1. 进程管理
   2. 存储器管理
   3. 设备管理

#### 中断和异常

1. 定义
   1. 中断：外中断，表示cpu执行指令的外部的事件
      1. 可屏蔽INTR
      2. 不可屏蔽NMI
   2. 异常：内中断，表示cpu执行指令内部的事件
      1. 故障
      2. 内陷
      3. 终止
2. 中断是在指令结束后检测，异常是指令执行时
3. 中断处理和子程序调用的比较
   1. 两者相互独立，没有明确关系
   2. 中断产生随机，子程序有call引起
   3. 子程序是软件处理，中断处理需要专门的硬件
   4. 中断地址有硬件向量法找到，子程序有call指令给出
   5. 两者都需要保护PC程序计数器

#### 系统调用

1. 定义：是操作系统提供给应用程序的接口。
2. 是一种特殊得到公共子程序
3. 功能
   1. 设备管理
   2. 文件管理
   3. 进程控制
   4. 进程通信
   5. 内存管理
4. 系统调用的过程
   1. 第一步
      1. 将系统调用号和所用参数压栈
      2. 执行陷入命令，转化为内核态
      3. 保护现场，PC，PSW，通用寄存器压栈
   2. 第二步
      1. 根据系统调用号找到处理子程序（系统调用的公共程序）的入口
   3. 第三步
      1. 恢复现场，返回中断进程或新进程
5. 常见的变态方式
   1. 系统调用
   2. 中断
   3. 发生错误
   4. 用户态执行特权命令

## 操作系统的结构

![image-20250601152446406](C:\Users\27545\AppData\Roaming\Typora\typora-user-images\image-20250601152446406.png)

## 操作系统引导

1. 过程
   1. 激活cpu，读取boot程序，执行BIOS内指令
   2. 硬件自检
   3. 加载带有操作系统的硬盘MBR，MBR引导区哪里找操作系统
   4. 扫描硬盘分区表，加载硬盘活动分区，MBR包含硬盘分区表
   5. 加载分区，引导记录PBR，PBR：分区引导记录，寻找并激活分区根目录的启动管理器
   6. 加载启动管理器
   7. 加载操作系统·

## 虚拟机

#### 基本概念

1. 利用虚拟化技术，将一台物理机器虚拟化为多台虚拟机器，通过特定的计算平台的实际物理特性，为用户提供抽象的，统一的，模拟的计算环境。
2. 第一类虚拟机
   1. 运行在最高特权级的程序
   2. 作为用户态的一个进程，不允许执行敏感指令
   3. 他的内核态为虚拟内核态
3. 第二类虚拟机
   1. 运行在宿主操作系统之上的操作系统

# 进程与线程

## 进程与线程

#### 进程的概念和特征

1. 进程实体：程序段，相关数据段，PCB三部分组成
2. 概念：是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位
3. 特征
   1. 动态性：最基本的特征
   2. 并发性
   3. 独立性：独立的运行，获得资源和调度
   4. 异步性

#### 进程的组成

1. 进程控制块
   1. 进程存在的唯一标志
   2. 内容
      1. 进程描述信息
         1. 进程标识符：PID
         2. 用户标识符：UID
      2. 进程控制和管理信息
         1. 进程当前状态
         2. 进程优先级
      3. 资源分配清单
         1. 用于说明有关内存地址空间或虚拟地址空间的状况
      4. 处理机相关信息
         1. CPU的相关信息
2. 程序段
   1. 程序段就是能被进程调度程序调度到CPU执行的程序代码段
   2. 多个程序可能运行同一程序
3. 数据段
   1. 可能是原始数据，也可能是中间和最终结果

#### 进程的状态和切换

1. 运行态：单CPU，每个时刻唯一
2. 就绪态：就绪态队列
3. 阻塞态：进程正在等待某一事件而暂停运行，可以通过不同原因形成不同阻塞队列
4. 创建态：申请PCB，填写控制和管理进程的信息，分配必须资源，最后插入就绪队列，（创建工作未完成则为创建态）
5. 终止态：进程正在从系统中消失，先转化为终止态，然后回收资源
6. **状态转换的事件**
   1. 就绪态——运行态：获得CPU资源
   2. 运行态——就绪态：时间片结束，被高优先级抢占
   3. 运行态——阻塞态：进程请求某一资源或者等待事件
   4. 阻塞态——就绪态：进程等待资源到来

#### 进程控制

1. 一般进程控制使用的程序段称为原语。
2. 进程的创建
   1. 运行父进程创建子进程
   2. 子进程继承父进程资源
   3. 过程
      1. 分配PID，申请PCB
      2. 分配资源
      3. 初始化PCB
      4. 进入就绪队列
   4. 触发条件
      1. 终端用户登录，作业调度，系统提供服务，用户程序的应用请求
3. 进程的终止
   1. 成因
      1. 正常结束，异常结束，外界干预
   2. 终止进程时的操作
      1. 根据PID，找到PCB，找到status
      2. 运行态则终止运行，让出CPU
      3. 存在子孙进程，先结束子孙进程
      4. 归还所有资源
      5. 将PCB在所在队列中删除
4. 进程的阻塞和唤醒
   1. 过程（原语）
      1. 找到PID，PCB
      2. 运行态，保护现场，改变为阻塞态，停止运行
      3. PCB插入阻塞等待队列，让出cpU
   2. 唤醒原语
      1. 等待队列找到PCB
      2. 移出等待队列，改为就绪态
      3. 加入就绪队列，等待调度

#### 进程的通信

1. 共享内存
   1. 基于数据结构的共享
   2. 基于存储区的共享
2. 消息传递
   1. 直接通信方式
      1. 发送进程直接发送接收进程的消息缓冲队列，接收进程从队列接收
   2. 间接通信
      1. 发送进程将消息发送到某个中间实体，接收进程从实体中接收消息
3. 管道通信
   1. 生产者消费者模式
      1. 满则只读，空则只写
      2. 互斥，同步，确定对方存在
   2. 问题
      1. 限制管道大小
      2. 读比写快
4. 信号
   1. 一种用于通知进程发生某个事件的机制
   2. 方式
      1. 内核给某个进程发送信号。
      2. 一个进程给另一个进程发送信号
   3. 处理方式
      1. 执行默认的信号处理程序
      2. 执行进程定义的信号处理程序

#### 线程和多线程模型

1. 线程的基本概念
   1. 基本cpu执行单位，有TID，PC，寄存器集合和堆栈组成
   2. 提高了系统利用率和吞吐量，更好的多道程序并发
2. 进程和线程的比较
   1. 调度
   2. 并发性
   3. 拥有资源
   4. 独立性
   5. 系统开销
   6. 支持多处理系统
3. 线程的属性
   1. 是一个轻型实体
   2. 不同线程可以执行相同程序
   3. 同一进程的各个线程共享所有资源
   4. 线程是cpu独立调度的单位
4. 线程的状态和切换
   1. 执行态
   2. 就绪态
   3. 阻塞态
5. 线程的组织和控制
   1. 线程控制块
      1. 线程标识符，一组寄存器，线程运行状态，优先级，线程专有存储区，堆栈指针
   2. 线程的创建
   3. 线程的终止
6. 线程的实现方式
   1. 用户级线程
      1. 用户可视的线程，线程管理内容在用户态执行
      2. 优点
         1. 不需要切换cpu状态
         2. 调度算法进程专用，进程可以为自己线程选择调度算法
         3. 用户级线程与操作系统无关
      3. 缺点
         1. 系统调用的阻塞问题，一个线程阻塞，则全部线程阻塞
         2. 不能发挥多cpu的优势，一个cpu只能运行一个线程
   2. 内核级线程
      1. 发挥多cpu的优势，同一进程的线程可以并行运行
      2. 一个阻塞，其他不阻塞
      3. 线程需要的数据结构和堆栈小，切换快，开销小
      4. 缺点：线程切换开销大
   3. 组合方式
      1. 线程库的方式
         1. 用户空间提供一个没有内核支持的库
         2. 实现由操作系统直接支持的内核级的一个库
7. 多线程模型
   1. 多对一
      1. 多个用户级映射到一个内核级线程
   2. 一对一
      1. 一个用户级映射一个内核级线程
   3. 多对多模型
      1. 将n个用户级映射到m个内核级，m>=n

## CPU调度

#### 调度的概念

1. 调度的基本概念
   1. 对cpu的分配
2. 调度的层次
   1. 三级调度
      1. 高级调度
         1. 外存队列中取一个或多个分配内存，建立线程，放入就绪队列
      2. 中级调度
         1. 引入中级调度的目的是提高内存的利用率和系统吞吐量
         2. 将不能运行的进程调入外存，变为挂起态
         3. 将可以运行的且内存有空闲时，变为就绪态
      3. 低级调度
         1. 将就绪态变为运行态
   2. 三级调度的联系
      1. 作业调度为进程活动做准备，进程调度是进程正常活动起来
      2. 中级调度将不能运行挂起
      3. 作业调度次数少，中级调度次数略多，低级最多
      4. 进程调度是最基本的

#### 进程调度的实现

1. 调度程序
   1. 用于调度和分派CPU的组件称为调度程序
   2. 组成
      1. 排队器：对就绪队列排队
      2. 分派器：对就绪队列进程分派CPU
      3. 上下文切换器：在对CPU切换时，将当前进程上下文和分派程序上下文保存到PCB，移出分派程序上下文，和新线程的CPU信息装入寄存器
2. 调度的时机和切换及过程
   1. 时机
      1. 创建新进程
      2. 进程正常结束和异常停止
      3. 进程因为IO请求，信号量操作，其他原因阻塞
   2. 不能进行切换的情况
      1. 在处理中断的过程中
      2. 在进行原子操作时
   3. 进程调度的方式
      1. 非抢占调度
         1. 操作简单，系统开销小，适合批处理系统
      2. 抢占调度
         1. 提高系统吞吐率和响应效率
3. 闲逛进程
   1. 系统没有就绪进程就执行闲逛进程
4. 两种线程的调度
   1. 用户级线程调度
      1. 进程调度程序决定线程运行
   2. 内核级线程
      1. 内核选择线程运行

#### 调度目标

1. CPU利用率 = CPU有效工作时间/CPU有效时间+CPU等待时间
2. 系统吞吐量：单位时间内CPU完成作业的数量
3. 周转时间 = 作业完成时间 - 作业提交时间
4. 平均周转时间 = 所有作业周转时间/作业数
5. 带权周转时间 = 作业周转时间/作业实际运行时间
6. 平均带权周转时间
7. 等待时间
8. 响应时间：请求到响应时间

#### 进程切换

1. 上下文切换
   1. 挂起一个进程，CPU上下文保存到PCB
   2. 将PCB移入相应队列
   3. 选择另一个进程执行
   4. 恢复新进程的CPU上下文
   5. 跳转到新进场的PC位置执行
2. 上下文切换的消耗
   1. 上下文切换通常是计算密集型的，消耗大量CPU时间
3. 上下文切换和模式切换
   1. 用户态和内核态的切换称为模式切换，不改变当前进程

#### CPU调度算法

1. 先来先服务调度算法
   1. 适用于作业调度和进程调度
   2. 不可剥夺算法
   3. 特点
      1. 算法简单，效率低
      2. 长作业有利，短作业不理
      3. 适用CPU繁忙，不利于IO繁忙
2. 短作业优先
   1. 适用作业和进程调度
   2. 特点
      1. 长作业不利，可能产生饥饿
      2. 未考虑作业紧迫
   3. 可能抢占，可能不抢占
3. 高响应比优先调度
   1. 响应比 = 等待时间 + 要求服务时间/要求服务时间
   2. 特点
      1. 等待时间相同，服务时间越短，响应比越高，利于短作业
      2. 要求服务时间相同，类似于FCFS
      3. 长作业不会饥饿
4. 优先级调度算法
   1. 都适用
   2. 非抢占优先级
   3. 抢占优先级
   4. 静态优先级
      1. 优先级不变
      2. 缺点：不够精确，可能导致优先级低的长时间不能运行
   5. 动态优先级
      1. 优先级随进程推进改变
   6. 优先级设置原则
      1. 系统进程>用户进程
      2. 交互式进程>非交互式进程
      3. IO进程>计算型进程
5. 时间片轮转算法
   1. 适用分时系统
   2. 每个进程运行一个时间片，然后进入就绪队列队尾，直到运行完成，通过时钟中断（时间片结束）唤醒调度
   3. 时间片大小影响因素
      1. 系统响应时间
      2. 就绪队列进程数目
      3. 系统处理能力
6. 多级队列调度算法
   1. 设置多个就绪队列，每个队列设置不同调度算法
7. 多级反馈队列调度算法
   1. 时间片和优先级的结合
   2. 思想
      1. 设置多个就绪队列，每个队列不同优先级
      2. 优先级高的队列时间片短
      3. 每个队列采用FCFS算法
      4. 按队列优先级接收调度
         1. 先是第一个队列，运行第一个线程后，将其放入下一队列的队尾
         2. 第一个队列空，运行第二个队列
   3. 优点
      1. 终端型用户：短作业优先
      2. 短批处理：周转时间短
      3. 长批处理：不会饥饿
8. 基于公平原则的调度算法
   1. 保证调度算法
      1. 多用户使用，每个用户分1/n时间，多进程，每个进程分1/n时间
      2. 操作系统必须具备
         1. 跟踪进程使用cpu时间
         2. 计算各个进程应获得多少cpu时间
         3. 计算已获得cpu时间和应获得cpu时间比值
         4. 调度比值最小的进程运行
   2. 公平分享调度算法
      1. 根据进程来分配CPU时间，可能对用户不公平（每个用户进程数不同）
9. <img src="C:\Users\27545\AppData\Roaming\Typora\typora-user-images\image-20250605165545102.png" alt="image-20250605165545102" style="zoom:25%;" />

#### 多处理机调度

1. 非对称多处理机
   1. 主机内核，从机用户
2. 对称多处理机
   1. 所有处理机相同
3. 亲和性和负载平衡
   1. 处理器亲和性：一个进程尽量运行在一个cpu
   2. 负载均衡：所有的CPU负载一致
4. 多处理机调度方案
   1. 公共就绪队列
      1. 所有CPU共享一个就绪队列
      2. 负载平衡好，处理器亲和性不好
   2. 软亲和
      1. 调度程序尽量保持在一个cpu
   3. 硬亲和
      1. 用户通过系统调用主动要求分配到固定cpu
   4. 私有就绪队列
      1. 每个cpu有自己的就绪队列
      2. 处理器亲和好，负载均衡不好
      3. 平衡负载
         1. 推迁移
            1. 将超载cpu线程推到空闲cpu
         2. 拉迁移
            1. 空闲cpu拉线程到自身

## 同步和互斥

#### 同步和互斥的基本概念

1. 临界资源
   1. 一次只能给一个进程使用的资源
   2. 访问过程
      1. 进入区：检查能否今日，设置临界区访问标志
      2. 临界区：临界区代码
      3. 退出区：将临界区访问标志移出
      4. 剩余区
2. 同步
   1. 表示某个任务需要多个进程，不同进程之间存在先后制约关系
3. 互斥
   1. 间接制约，一个进程进入访问资源，退出后，另一个才能进入
4. 实现互斥的准则
   1. 空闲让进
   2. 忙则等待
   3. 有限等待
   4. 让权等待

#### 实现临界区互斥的基本方法

1. 软件实现
   1. 单标志法
      1. 进入区：while(turn != 0)
      2. 退出区：turn = 1
      3. 表示进入时，检查标志是否为对应编号，退出时，将标志设为另一个进程的编号
      4. 问题
         1. 违背空闲让进
   2. 双标志检查法
      1. 进入区：while(flag[1]);flag[0] = true;
      2. 退出区：flag[0] = false;
      3. 设置数组，flag[i] 表示第i个进程的访问意愿，进入时，检查对方是否想进，然后设置自己想进，退出时，设置自己不想进
      4. 问题
         1. 违背忙则等待
   3. 双标志后检查法
      1. 先检查自己标志，再检查对方标志
      2. 进入区：两行代码互换
      3. 退出区相同
      4. 问题
         1. 违背空闲让进
         2. 违背有限等待
   4. peterson算法
      1. 进入区：flag[0] =  true；turn = 1；while（flag[1] && turn == 1)；
      2. 退出区相同
      3. 先表达自己意愿，设置临界区标志，检查flag和临界区标志，至少有一个可以进入
      4. 问题
         1. 违背了让权等待
2. 硬件实现
   1. 中断屏蔽
      1. 通过开关中断来保证互斥的进行
      2. 缺点
         1. 限制了cpu的交替执行程序的能力，系统效率低
         2. 不适用于多处理系统，一个cpu不能影响其他
         3. 交给用户执行关中断不安全
   2. 硬件指令方法TS指令
      1. ts指令功能：读出标志，设置标志为真
      2. 进入区：while TestAndSet（&lock)，检查是否上锁
      3. 退出区：解锁
      4. 问题
         1. 不能让权等待
   3. 硬件指令方法Swap指令
      1. 功能：交换两个字节的内容
      2. 进入区：bool key = true;while(key);swap(lock,key)
      3. 退出区：lock = false
      4. 优点
         1. 简单，适用任意数量进程
         2. 支持多个临界区
      5. 缺点
         1. 不能让权等待
         2. 饥饿现象

#### 互斥锁

1. 互斥锁：解决临界区最简单工具，使用两个函数获得释放锁，缺点是忙等待
2. 适用于多处理器系统

#### 信号量

1. 用于解决同步和互斥的问题
2. 通过wait（P)，signal（V）操作访问
3. 整型信号量
   1. 整型表示资源数量的个数S
   2. 进入区：资源数不够则一直等待，够则S-1
   3. 退出区：S+1
   4. 问题
      1. 存在忙等
4. 记录型信号量
   1. 整型变量加进程链表
   2. 进入区：资源数量够则S-1，不够则将申请进程进入阻塞进程链表
   3. 退出区：资源数S+1，唤醒阻塞进程的第一个进程
5. 利用信号量实现互斥
   1. 多个进程访问临界资源时
      1. 准备时加锁，P
      2. 结束时解锁，V
6. 利用信号量实现同步
   1. 一个进程解锁，V，一个进程加锁P
   2. 一个进程释放资源，另外一个进程接收资源
   3. 一个进程在前，另一个进程在后
7. 利用信号量实现前驱关系
   1. 每一个前驱关系都是一个同步的问题
8. 分析进程同步和互斥问题的方法步骤
   1. 关系分析：分析所有进程的同步和互斥关系
   2. 整理思路
   3. 设置信号量

#### 经典同步问题

1. 生产者消费者问题
   1. 缓冲区是互斥资源，所有进程都互斥访问
   2. 同步
      1. 缓冲区空，生产者生产
      2. 缓冲区满，消费者消费
   3. 生产者
      1. 互斥：PV
      2. 同步进入：减少一个空缓冲单元
      3. 同步退出：增加一个满缓冲区
   4. 消费者
      1. 互斥：PV
      2. 同步进入：减少一个满缓冲区
      3. 同步退出：增加一个空缓冲区
   5. **当缓冲区只有一个时，不需要互斥访问**
2. 读者写者问题
   1. 允许同时读，不允许同时写，不允许同时读写
   2. 设置信号量mutex表示count互斥访问，count用于记录同时访问读者数量
   3. 设置rw表示读写间，写写间互斥访问，count为0表示可以写，非零不可写，在count中设置rw互斥
   4. 互斥
      1. 写和其他写，其他读
   5. 同步
      1. 写完，读
      2. 读完，写
   6. 写进程
      1. 写写互斥：PV
   7. 读进程
      1. 对count计数操作进行原子操作，不可以同时访问
      2. 进入区：如果count为0，表示当前为第一个进入读者，rw上锁
      3. 退出区：如果count为0，表示当前为最后一个退出读者，rw解锁
   8. 正常情况存在写进程饥饿
   9. **改进**
      1. 在写进程的开始和结束增加PV（W)，表示对共享文件的访问权限
      2. 在读进程的开始和中间增加PV（w)，表示在每个读进程的中间都可以允许写进程获得w导致后续读进程阻塞，然后执行完当前读进程后，既可以执行写进程
3. 哲学家问题
   1. 互斥问题
      1. 五个哲学家和左右邻居对于中间的筷子是互斥访问的
      2. 同步：一个哲学家释放左手筷子，左边哲学家即可以获得这个筷子


#### 管程

1. 定义
   1. 一种只可以互斥访问的共享资源
2. 特点
   1. 将共享资源封装起来
   2. 每次只运行一个进程进入管程
3. 条件变量
   1. 用于表示在管程中阻塞的进程的原因
   2. x.wait,表示进程阻塞时，将进程插入阻塞队列
   3. X.signal，表示进程满足条件后，将进程唤醒

## 死锁

#### 死锁的概念

1. 死锁的定义
   1. 多个进程同时等待对方手中的资源
2. 死锁和饥饿
   1. 饥饿原因
      1. 分配策略不公
   2. 共同点
      1. 发生饥饿的线程可以只有一个
      2. 死锁的线程不止一个
      3. 饥饿的线程位于就绪态或者阻塞态（等待外部设备），死锁的线程位于阻塞态
3. 死锁产生原因
   1. 系统资源的竞争
   2. 进程推进顺序非法
4. 死锁产生的必要条件
   1. 互斥
   2. 不可剥夺
   3. 请求并保持
   4. 循环等待
5. 死锁的处理策略
   1. 死锁预防
   2. 避免死锁
   3. 死锁的检测和解除

#### 死锁预防

1. 破坏互斥条件
   1. 将互斥资源改造为共享使用
2. 破坏不可剥夺条件
3. 破坏请求并保持条件
   1. 静态分配：进程运行前一次申请所有资源，否则不能执行
   2. 允许进程获得部分资源执行，但是再次获得资源需要先释放已有资源
4. 破坏循环等待条件
   1. 顺序资源分配法：所有资源都有编号，申请同一编号资源一次申请完，不同资源编号从小到大申请

#### 死锁避免

1. 系统安全状态
   1. 允许系统动态的申请资源
   2. 能找到一个序列可以执行完所有进程，即为安全状态
   3. 不能为不安全
2. 银行家算法
   1. 可用资源available，m类，每类有k个可用
   2. 最大需求矩阵max：每个进程需要的m类资源的个数
   3. 分配矩阵：已经分配给每个进程的矩阵数量
   4. 需求矩阵：每个矩阵还需要的矩阵数量
   5. 需求 = 最大-分配
   6. 过程
      1. 先判断需求矩阵和请求矩阵大小比较，请求需要小于需求
      2. 比较请求和可用大小，大于则循环比较，全部大于则错误
      3. 小于则将资源分配给此线程，并修改可用，分配，需求矩阵的值
3. 安全性算法
   1. 设置工作向量表示剩余可用资源数
   2. 初始时安全序列为空
   3. 从需求矩阵找出进程不在安全序列且小于等于工作向量的进程，找不到则为不安全状态
   4. 找到则允许此线程，然后work资源+= 请求资源，然后继续执行3，直到所有进程都进入序列

#### 死锁的检测和解除

1. 死锁的检测
   1. 请求边：进程到资源
   2. 分配边：资源到进程
   3. 过程
      1. 找到不阻塞且不孤立的进程，消去所有边
      2. 然后重复1
      3. 如果可以全部消除，则为可完全简化，不死锁，反之死锁
2. 死锁解除
   1. 资源剥夺法
   2. 撤销进程法
   3. 进程回退法

# 内存管理

## 内存管理概念

#### 内存管理的基本原理和请求

1. 内存管理是操作系统设计中最重要最复杂的内容之一
2. 功能
   1. 内存空间的分配和回收
   2. 地址转换：逻辑到物理
   3. 内存空间的扩充：虚拟存储技术
   4. 内存共享
   5. 存储保护：各个进程互不干扰
3. 逻辑地址和物理地址
   1. 逻辑地址：模块从0号单元开始编址的逻辑地址空间
   2. 物联地址：内存中物理单元的集合
   3. 地址的重定位
   4. 内存管理部件MMU：转化逻辑为物理地址
4. 程序的链接和装入
   1. 编译：将用户源代码编译为若干目标模块
   2. 链接：将他们的库函数链接起来形成一个完整的装入模块
      1. 静态链接：运行前链接为一个装入模块，不改变
      2. 装入时动态链接：装入内存时，边装入边链接，便于共享
      3. 运行时动态链接：执行到哪一块，连接哪一块，省内存
   3. 装入：装入程序将装入模块装入内存运行
      1. 绝对装入：只适用于单道程序环境，逻辑等于物理地址
      2. 可重定位装入：静态重定位，装入时将逻辑地址改为物理地址，之后无法更改
      3. 动态运行时装入：动态重定位，装入内存不修改，直到运行时，根据重定位寄存器加上相对地址求出物理地址
         1. 可以将程序分配到不连续的存储区
         2. 便于程序段的共享
5. 进程的内存映像
   1. 代码段：二进制代码，只读数据，const常量
   2. 数据段：全局和静态变量
   3. 进程控制块：系统区
   4. 堆：动态分配的变量
   5. 栈：函数调用
6. 内存保护
   1. 在cpu中设置一个上下限寄存器，存放用户进程在主存的下限和上限地址
   2. 重定位寄存器（基地址寄存器），界地址寄存器（限长寄存器）进行越界检测。
      1. 重定位先加，然后界地址寄存器比
7. 内存共享
   1. 可重入代码：纯代码，就是可以共享的代码，不可以被修改，只读
   2. 实现：内存映射文件，不同逻辑地址映射到一个物理地址
8. 内存的分配和回收

#### 连续分配管理

1. 连续分配：为用户分配一个连续的内存空间
2. 单一连续分配
   1. 内存分为用户区，系统区
   2. 定义：一个用户程序独占整个用户区
   3. 优点：简单，没有外部碎片，不需要内存保护
   4. 缺点：只能用于单程序，单用户操作系统，有内部碎片，内存利用率低
3. 固定分区分配
   1. 分区大小相等：缺乏灵活性，小过大，大过小
   2. 分区大小不等：划分为多个小，适量中，少多
   3. 分区使用表：记录分区的起始地址，大小，状态
   4. **固定分配缺点**
      1. 太大无法装入
      2. 太小时产生内部碎片（分配的空间大于实际使用的空间)
4. 动态分区分配
   1. 动态分区分配的基本原理
      1. 可变分区分配，根据进程的大小为其分配合适的内存块
   2. 容易产生外部碎片
   3. 紧凑技术可以解决外部碎片：但是耗费时间
   4. 管理方式
      1. 空闲分区链：存放一个链表连接所有未使用的空闲分区，
      2. 新进程的分配
         1. 从空闲分区中找到一块大于进程所需的空间
         2. 将其中一块分割给进程
      3. 进程的回收
         1. 回收后前面有一块空闲，将两个分区合并
         2. 回收后后面有，合并
         3. 回收后，前后都有，合并
         4. 回收后，前后没有，不合并
         5. 合并是将起始地址，分区大小改变
   5. 基于顺序搜索的分配算法
      1. 首次适应算法
         1. 空间按照地址递增的顺序排序，每次从前到后遍历分区表，将第一个合适的内存分割给进程
         2. 优点：便于后续大进程的装入
         3. 缺点：低地址存在很多外部碎片，增加时间开销
      2. 临近适应算法
         1. 空间分区按照地址递增的顺序排序，每次从上次结束的位置开始遍历，将第一个分割给进程
         2. 缺点：会导致所有位置都有外部碎片
      3. 最佳适应算法
         1. 分区按照大小递增的顺序排序，每次从前到后遍历分区表，第一个分割给进程
         2. 优点：找到第一个满足进程大小的分区，剩余很多大分区
         3. 缺点：产生更多外部碎片，时间开销大
      4. 最坏适应算法
         1. 分区按照大小递减的顺序排序，每次从前到后遍历分区表，第一个分割给进程
         2. 缺点：很快没有了大的分区块
   6. 基于索引搜索的分配算法
      1. 思想：根据大小对分区分类，相同大小单独设立链表管理，设置一个表管理这些链表
      2. 快速适应算法
         1. 根据进程大小，索引表找到最小空闲分区分配第一个
         2. 优点：查找效率高，不会产生内存碎片
         3. 缺点：回收分区时，合并复杂，算法复杂，系统开销大
      3. 伙伴系统
         1. 规定所有分区大小为2的指数次，相同次为一个链表，总体为一张表
         2. 为进程分配一个指数次最小的分区
         3. 回收时，相邻合并更大分区
      4. 哈希算法
         1. 根据分区大小创建哈希函数
         2. 每个关键字对应一个链表存
         3. 查找时，根据函数找到分区
   7. **连续分配的缺点：当请求分区大的时候无法实现**

#### 基本分页存储管理

1. 分页：页框，页帧，物理块
2. 分页存储的几个基本概念
   1. 页面和页面大小
      1. 页号：逻辑地址空间的页面编号
      2. 页框号：内存空间的每个页框也有一个编号
      3. 页面大小为2的次幂
   2. 地址结构
      1. 页号+页内偏移量
   3. 页表
      1. 每个页面对应一个页表项，页表项记录了页号和块号
      2. 页表的作用是实现页号到物理块号的映射
3. 基本地址变换结构
   1. 将逻辑地址转换为内存中的物理地址
   2. 页表寄存器：记录页表内存起始地址F和页表长度M
   3. 计算过程
      1. 根据逻辑地址计算出页号P = A/L,页内偏移量W = A%L，A为逻辑地址，L页面大小
      2. 判断页号是否越界，若页号P大于页表长度M，产生越界中断
      3. 在页表中查询页号对应得到页表项，确定页表项内容，页号P对应页表项地址 = 页表始址+页号*页表项长度，页表项内容即为物理块号b
      4. 计算物理地址 = bL + M，块号乘以页表大小+偏移量

   4. 主要问题
      1. 地址转换必须够快
      2. 页表不能太大

4. 具有快表的地址变换机构
   1. 过程
      1. CPU给出逻辑地址，硬件地址转换，将页号和快表中的页号比较
      2. 找到匹配页号则直接取出对应物理块号，求出物理地址
      3. 未找到匹配，则同等于没有快表计算过程

5. 两级页表
   1. 离散分配，用一个索引表记录各个页表位置
   2. 将部分页表调入内存，其他存入磁盘
   3. 过程
      1. 通过一级页号找到外层页表中位置
      2. 在外层页表中找到二层页表的对应页表，通过二级页号找到页表对应页表项
      3. 在此页表项中找到对应三级页表项物理地址，通过物理地址和页内偏移量找到对应位置


#### 基本分段存储管理

1. 分段
   1. 分段将用户进程划分为大小不等的段，段内连续，段间不连续
   2. 段号+段内偏移量
2. 段表
   1. 段号+段长+始址
3. 地址变换机构
   1. 过程
      1. 逻辑地址取出前几位段号，后几位为偏移量
      2. 判断是否越界
      3. 在段表中查询段号对应段表项 = 段表始址+段号*段表项长度，取出段长判断越界
      4. 物理地址 = 物理始址+偏移量
4. 分段和分页对比
   1. 页是信息的物理单位（对用户不可见），段是信息的逻辑单位（用户可见）
   2. 页的大小有系统决定，段的长度不固定
   3. 分页管理的地址空间是一维的，分段管理的地址空间是二维的
5. 段的共享保护
   1. 共享段表
      1. 段号，段长，内存始址，状态位，外存地址，共享进程计数

#### 段页存储管理

1. 逻辑地址 = 段号+页号+页内偏移
2. 过程
   1. 通过段号查找段表位置 ，段表项地址 = 段号*段表项大小+段内起始地址
   2. 通过段表找到对应页表
   3. 通过页号找到对应页表项位置 = 页号*页表项大小+页表始址
   4. 页表项内物理始址，物理地址 = 物理始址+偏移量

## 虚拟内存管理

#### 虚拟内存的基本概念

1. 传统存储管理方式的特征
   1. 一次性：全部装入才能运行
   2. 驻留性：需要一直在内存中停留
2. 局部性原理
3. 虚拟存储器的定义和特征
   1. 多次性：大作业可以分批多次调入内存
   2. 对换性：作业运行时可以将暂时不用的换出
   3. 虚拟性
4. 虚拟内存技术的实现
   1. 请求分页管理
   2. 请求分段管理
   3. 请求段页式管理

#### 请求分页管理方式

1. 页表机制
   1. 页号，物理块号，状态位，访问字段，修改位，外存地址
   2. 状态位：标记是否进入内存
   3. 访问字段：记录本页在一段时间内的访问次数
   4. 修改位：标记该页在调入内存后是否被修改过
   5. 外存地址：记录该页在外存的存放地址
2. 缺页中断机构
   1. 访问页面不在内存需要产生缺页中断
   2. 一条指令执行期间发生中断表示为内部中断，可以发生多次缺页中断
3. 地址变换机构
   1. 过程
      1. 判断越界
      2. 检查快表，在则直接在快表中修改，并修改访问位和修改位，形成物理地址，地址变换结束
      3. 如果在快表则访问页表
      4. 页表不在内存时，发生中断
         1. 保留cpu现场
         2. 外存中找到缺页，判断内存满？
            1. 内存满则换页，判断内存是否修改，修改则写回
         3. 操作系统命令CPU从外存读缺页
         4. 启动IO硬件
         5. 将页换入内存
         6. 修改页表
      5. 修改快表，在快表中做相关处理
4. 页框分配
   1. 驻留集大小
      1. 驻留集越小，驻留在内存中的进程越多，可以提高多道程序的并发度
      2. 页框太少，导致缺页率增加
      3. 驻留集越大，并发度降低，缺页率减少
   2. 内存分配策略
      1. 固定分配局部置换
         1. 每个进程分配固定数量物理块，缺页则从已有物理块分给
      2. 可变分配全局置换
         1. 每个进程分配一定量物理块，缺页则从空闲物理块中分出一块给相关进程
      3. 可变分配局部置换
         1. 每个进程分配一定量，通过缺页情况适当修改进程物理块数
   3. 物理调入算法
      1. 平均分配算法
      2. 按比例分配算法
      3. 优先权分配算法
   4. 调入页面的时机
      1. 预调页策略：预先调入内存
      2. 请求调页策略：进程运行中需要访问的页面不在内存，提出请求，系统调入内存，增加IO
   5. 从何处调入页面
      1. 系统有足够多的对换区：所有有关调入对换区
      2. 系统缺少足够的对换区：不修改直接调，修改过的对换区调
      3. UNIX方式：未运行过的放入文件区，运行过的放入对换区
   6. 如何调入页面
      1. 过程
         1. 缺页中断
         2. 缺页中断响应程序
         3. 内存未满，启动IO
            1. 置换算法
            2. 未修改直接换，修改过写回
         4. 修改页表，存在位

#### 页面置换算法

1. 最佳置换算法
   1. 将以后永不使用的页面或者最长时间内不使用的页面置换
   2. 缺点：不可实现
2. 先进先出算法
   1. 置换最早进入的页面
   2. Bleady异常：缺页次数不减反增
3. 最近最久未使用置换算法
   1. LRU算法性能较好，但是需要寄存器和栈
4. 时钟置换算法
   1. 简单的时钟置换算法
      1. 设置一个访问位
      2. 也叫最近未使用算法
   2. 改进的时钟置换算法
      1. 增加修改位，通过修改位和访问位来置换
      2. 过程
         1. 第一次扫描访问和修改都为0的页面
         2. 第二次扫描访问为0的页面并将扫描过的访问改为0
         3. 第三次扫描修改为0的页面，并将扫描的修改位改为0
         4. 第四次扫描都为0的页面

#### 抖动和工作集

1. 抖动
   1. 刚刚换出换入的页面需要换入换出
2. 工作集
   1. 某段时间内进程访问的页面集合
   2. 驻留集不能小于工作集

#### 页框回收

1. 页面缓冲算法
   1. 换入换出的影响因素
      1. 置换算法
      2. 已修改的页面写回的频率
      3. 磁盘读入内存的频率
   2. 两个链表
      1. 空闲页面链表：进程读入直接给
      2. 修改页面链表：修改写回的页面先放入这里，慢慢写回
   3. 页框回收

#### 内存映射文件

1. 内存映射文件是操作系统对应用程序提供的一个系统调用
2. 在内存中映射文件内容，访问时读入内存，修改后再释放进程时写回
3. 共享内存：映射相同的文件到不同的进程
4. 优点：
   1. 编程简单
   2. 多进程共享

#### 虚拟存储器性能影响因素

1. 缺页率是主要因素
   1. 页面大小，物理块数（驻留集），置换算法，程序的局部性程度

#### 地址翻译

1. 
